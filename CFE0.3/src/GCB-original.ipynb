{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' #TODO\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "from tqdm import tqdm, trange\n",
    "import multiprocessing\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from parser import DFG_python,DFG_java,DFG_ruby,DFG_go,DFG_php,DFG_javascript\n",
    "from parser import (remove_comments_and_docstrings,\n",
    "                   tree_to_token_index,\n",
    "                   index_to_code_token,\n",
    "                   tree_to_variable_index)\n",
    "from tree_sitter import Language, Parser\n",
    "dfg_function={\n",
    "    'python':DFG_python,\n",
    "    'java':DFG_java,\n",
    "    'ruby':DFG_ruby,\n",
    "    'go':DFG_go,\n",
    "    'php':DFG_php,\n",
    "    'javascript':DFG_javascript\n",
    "}\n",
    "\n",
    "#load parsers\n",
    "parsers={}        \n",
    "for lang in dfg_function:\n",
    "    LANGUAGE = Language('parser/my-languages.so', lang)\n",
    "    parser = Parser()\n",
    "    parser.set_language(LANGUAGE) \n",
    "    parser = [parser,dfg_function[lang]]    \n",
    "    parsers[lang]= parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2021 12:57:20 - WARNING - __main__ -   device: cuda, n_gpu: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adam_epsilon=1e-08, code_length=386, config_name='microsoft/graphcodebert-base', data_flow_length=128, device=device(type='cuda'), do_eval=False, do_test=False, do_train=True, epochs=1, eval_batch_size=16, eval_data_file='../data/clonedetection/valid.txt', evaluate_during_training=True, gradient_accumulation_steps=4, learning_rate=2e-05, max_grad_norm=1.0, max_steps=-1, model_name_or_path='microsoft/graphcodebert-base', n_gpu=1, output_dir='saved_models', seed=123456, test_data_file='../data/clonedetection/test.txt', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=4, train_data_file='../data/clonedetection/train.txt', warmup_steps=0, weight_decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Required parameters\n",
    "parser.add_argument(\"--train_data_file\", default='../data/clonedetection/train.txt', type=str,\n",
    "                    help=\"The input training data file (a text file).\")\n",
    "parser.add_argument(\"--output_dir\", default='saved_models', type=str,\n",
    "                    help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "\n",
    "## Other parameters\n",
    "parser.add_argument(\"--eval_data_file\", default='../data/clonedetection/valid.txt', type=str,\n",
    "                    help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n",
    "parser.add_argument(\"--test_data_file\", default='../data/clonedetection/test.txt', type=str,\n",
    "                    help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n",
    "\n",
    "parser.add_argument(\"--model_name_or_path\", default='microsoft/graphcodebert-base', type=str,\n",
    "                    help=\"The model checkpoint for weights initialization.\")\n",
    "\n",
    "parser.add_argument(\"--config_name\", default='microsoft/graphcodebert-base', type=str,\n",
    "                    help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "parser.add_argument(\"--tokenizer_name\", default='microsoft/graphcodebert-base', type=str,\n",
    "                    help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "\n",
    "parser.add_argument(\"--code_length\", default=386, type=int,\n",
    "                    help=\"Optional Code input sequence length after tokenization.\") \n",
    "parser.add_argument(\"--data_flow_length\", default=128, type=int,\n",
    "                    help=\"Optional Data Flow input sequence length after tokenization.\") \n",
    "parser.add_argument(\"--do_train\", action='store_true',\n",
    "                    help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\", action='store_true',\n",
    "                    help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\"--do_test\", action='store_true',\n",
    "                    help=\"Whether to run eval on the dev set.\")    \n",
    "parser.add_argument(\"--evaluate_during_training\", action='store_true',\n",
    "                    help=\"Run evaluation during training at each logging step.\")\n",
    "\n",
    "parser.add_argument(\"--train_batch_size\", default=4, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for training.\")\n",
    "parser.add_argument(\"--eval_batch_size\", default=16, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "parser.add_argument('--gradient_accumulation_steps', type=int, default=4,\n",
    "                    help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "parser.add_argument(\"--learning_rate\", default=2e-5, type=float,\n",
    "                    help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                    help=\"Weight deay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                    help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
    "                    help=\"Max gradient norm.\")\n",
    "parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
    "                    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
    "                    help=\"Linear warmup over warmup_steps.\")\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=123456,\n",
    "                    help=\"random seed for initialization\")\n",
    "parser.add_argument('--epochs', type=int, default=1,\n",
    "                    help=\"training epochs\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_known_args()[0]\n",
    "args.do_train = True\n",
    "args.evaluate_during_training = True\n",
    "\n",
    "# Setup CUDA, GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "args.device = device\n",
    "print(args)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',datefmt='%m/%d/%Y %H:%M:%S',level=logging.INFO)\n",
    "logger.warning(\"device: %s, n_gpu: %s\",device, args.n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "config = RobertaConfig.from_pretrained(args.config_name if args.config_name else args.model_name_or_path)\n",
    "config.num_labels = 1\n",
    "tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove comments, tokenize code and extract dataflow                                        \n",
    "def extract_dataflow(code, parser,lang):\n",
    "    #remove comments\n",
    "    try:\n",
    "        code=remove_comments_and_docstrings(code,lang)\n",
    "    except:\n",
    "        pass    \n",
    "    #obtain dataflow\n",
    "    if lang==\"php\":\n",
    "        code=\"<?php\"+code+\"?>\"    \n",
    "    try:\n",
    "        tree = parser[0].parse(bytes(code,'utf8'))    \n",
    "        root_node = tree.root_node  \n",
    "        tokens_index=tree_to_token_index(root_node)     \n",
    "        code=code.split('\\n')\n",
    "        code_tokens=[index_to_code_token(x,code) for x in tokens_index]  \n",
    "        index_to_code={}\n",
    "        for idx,(index,code) in enumerate(zip(tokens_index,code_tokens)):\n",
    "            index_to_code[index]=(idx,code)  \n",
    "        try:\n",
    "            DFG,_=parser[1](root_node,index_to_code,{}) \n",
    "        except:\n",
    "            DFG=[]\n",
    "        DFG=sorted(DFG,key=lambda x:x[1])\n",
    "        indexs=set()\n",
    "        for d in DFG:\n",
    "            if len(d[-1])!=0:\n",
    "                indexs.add(d[1])\n",
    "            for x in d[-1]:\n",
    "                indexs.add(x)\n",
    "        new_DFG=[]\n",
    "        for d in DFG:\n",
    "            if d[1] in indexs:\n",
    "                new_DFG.append(d)\n",
    "        dfg=new_DFG\n",
    "    except:\n",
    "        dfg=[]\n",
    "    return code_tokens,dfg\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "             input_tokens_1,\n",
    "             input_ids_1,\n",
    "             position_idx_1,\n",
    "             dfg_to_code_1,\n",
    "             dfg_to_dfg_1,\n",
    "             input_tokens_2,\n",
    "             input_ids_2,\n",
    "             position_idx_2,\n",
    "             dfg_to_code_2,\n",
    "             dfg_to_dfg_2,\n",
    "             label,\n",
    "             url1,\n",
    "             url2\n",
    "\n",
    "    ):\n",
    "        #The first code function\n",
    "        self.input_tokens_1 = input_tokens_1\n",
    "        self.input_ids_1 = input_ids_1\n",
    "        self.position_idx_1=position_idx_1\n",
    "        self.dfg_to_code_1=dfg_to_code_1\n",
    "        self.dfg_to_dfg_1=dfg_to_dfg_1\n",
    "        \n",
    "        #The second code function\n",
    "        self.input_tokens_2 = input_tokens_2\n",
    "        self.input_ids_2 = input_ids_2\n",
    "        self.position_idx_2=position_idx_2\n",
    "        self.dfg_to_code_2=dfg_to_code_2\n",
    "        self.dfg_to_dfg_2=dfg_to_dfg_2\n",
    "        \n",
    "        #label\n",
    "        self.label=label\n",
    "        self.url1=url1\n",
    "        self.url2=url2\n",
    "        \n",
    "\n",
    "def convert_examples_to_features(item):\n",
    "    #source\n",
    "    url1,url2,label,tokenizer, args,cache,url_to_code=item\n",
    "    parser=parsers['java']\n",
    "    \n",
    "    for url in [url1,url2]:\n",
    "        if url not in cache:\n",
    "            func=url_to_code[url]\n",
    "            \n",
    "            #extract data flow\n",
    "            code_tokens,dfg=extract_dataflow(func,parser,'java')\n",
    "            code_tokens=[tokenizer.tokenize('@ '+x)[1:] if idx!=0 else tokenizer.tokenize(x) for idx,x in enumerate(code_tokens)]\n",
    "            ori2cur_pos={}\n",
    "            ori2cur_pos[-1]=(0,0)\n",
    "            for i in range(len(code_tokens)):\n",
    "                ori2cur_pos[i]=(ori2cur_pos[i-1][1],ori2cur_pos[i-1][1]+len(code_tokens[i]))    \n",
    "            code_tokens=[y for x in code_tokens for y in x]  \n",
    "            \n",
    "            #truncating\n",
    "            code_tokens=code_tokens[:args.code_length+args.data_flow_length-3-min(len(dfg),args.data_flow_length)][:512-3]\n",
    "            source_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "            source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "            position_idx = [i+tokenizer.pad_token_id + 1 for i in range(len(source_tokens))]\n",
    "            dfg=dfg[:args.code_length+args.data_flow_length-len(source_tokens)]\n",
    "            source_tokens+=[x[0] for x in dfg]\n",
    "            position_idx+=[0 for x in dfg]\n",
    "            source_ids+=[tokenizer.unk_token_id for x in dfg]\n",
    "            padding_length=args.code_length+args.data_flow_length-len(source_ids)\n",
    "            position_idx+=[tokenizer.pad_token_id]*padding_length\n",
    "            source_ids+=[tokenizer.pad_token_id]*padding_length      \n",
    "            \n",
    "            #reindex\n",
    "            reverse_index={}\n",
    "            for idx,x in enumerate(dfg):\n",
    "                reverse_index[x[1]]=idx\n",
    "            for idx,x in enumerate(dfg):\n",
    "                dfg[idx]=x[:-1]+([reverse_index[i] for i in x[-1] if i in reverse_index],)    \n",
    "            dfg_to_dfg=[x[-1] for x in dfg]\n",
    "            dfg_to_code=[ori2cur_pos[x[1]] for x in dfg]\n",
    "            length=len([tokenizer.cls_token])\n",
    "            dfg_to_code=[(x[0]+length,x[1]+length) for x in dfg_to_code]        \n",
    "            cache[url]=source_tokens,source_ids,position_idx,dfg_to_code,dfg_to_dfg\n",
    "\n",
    "        \n",
    "    source_tokens_1,source_ids_1,position_idx_1,dfg_to_code_1,dfg_to_dfg_1=cache[url1]   \n",
    "    source_tokens_2,source_ids_2,position_idx_2,dfg_to_code_2,dfg_to_dfg_2=cache[url2]   \n",
    "    return InputFeatures(source_tokens_1,source_ids_1,position_idx_1,dfg_to_code_1,dfg_to_dfg_1,\n",
    "                         source_tokens_2,source_ids_2,position_idx_2,dfg_to_code_2,dfg_to_dfg_2,\n",
    "                         label,url1,url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2021 12:57:27 - INFO - __main__ -   Creating features from index file at ../data/clonedetection/train.txt \n",
      "100%|█████████████████████████████████████████| 160/160 [00:03<00:00, 45.20it/s]\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, args, file_path='train'):\n",
    "        self.examples = []\n",
    "        self.args=args\n",
    "        index_filename=file_path\n",
    "        \n",
    "        #load index\n",
    "        logger.info(\"Creating features from index file at %s \", index_filename)\n",
    "        url_to_code={}\n",
    "        with open('/'.join(index_filename.split('/')[:-1])+'/data.jsonl') as f:\n",
    "            for line in f:\n",
    "                line=line.strip()\n",
    "                js=json.loads(line)\n",
    "                url_to_code[js['idx']]=js['func']\n",
    "                \n",
    "        #load code function according to index\n",
    "        data=[]\n",
    "        cache={}\n",
    "        f=open(index_filename)\n",
    "        with open(index_filename) as f:\n",
    "            for line in f:\n",
    "                line=line.strip()\n",
    "                url1,url2,label=line.split('\\t')\n",
    "                if url1 not in url_to_code or url2 not in url_to_code:\n",
    "                    continue\n",
    "                if label=='0':\n",
    "                    label=0\n",
    "                else:\n",
    "                    label=1\n",
    "                data.append((url1,url2,label,tokenizer, args,cache,url_to_code))\n",
    "                \n",
    "        #only use 10% valid data to keep best model        \n",
    "        if 'valid' in file_path:\n",
    "            data=random.sample(data,int(len(data)*0.1))\n",
    "        \n",
    "        data=random.sample(data,16*10) #TODO\n",
    "            \n",
    "        #convert example to input features    \n",
    "        self.examples=[convert_examples_to_features(x) for x in tqdm(data,total=len(data))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        #calculate graph-guided masked function\n",
    "        attn_mask_1= np.zeros((self.args.code_length+self.args.data_flow_length,\n",
    "                        self.args.code_length+self.args.data_flow_length),dtype=np.bool)\n",
    "        #calculate begin index of node and max length of input\n",
    "        node_index=sum([i>1 for i in self.examples[item].position_idx_1])\n",
    "        max_length=sum([i!=1 for i in self.examples[item].position_idx_1])\n",
    "        #sequence can attend to sequence\n",
    "        attn_mask_1[:node_index,:node_index]=True\n",
    "        #special tokens attend to all tokens\n",
    "        for idx,i in enumerate(self.examples[item].input_ids_1):\n",
    "            if i in [0,2]:\n",
    "                attn_mask_1[idx,:max_length]=True\n",
    "        #nodes attend to code tokens that are identified from\n",
    "        for idx,(a,b) in enumerate(self.examples[item].dfg_to_code_1):\n",
    "            if a<node_index and b<node_index:\n",
    "                attn_mask_1[idx+node_index,a:b]=True\n",
    "                attn_mask_1[a:b,idx+node_index]=True\n",
    "        #nodes attend to adjacent nodes \n",
    "        for idx,nodes in enumerate(self.examples[item].dfg_to_dfg_1):\n",
    "            for a in nodes:\n",
    "                if a+node_index<len(self.examples[item].position_idx_1):\n",
    "                    attn_mask_1[idx+node_index,a+node_index]=True  \n",
    "                    \n",
    "        #calculate graph-guided masked function\n",
    "        attn_mask_2= np.zeros((self.args.code_length+self.args.data_flow_length,\n",
    "                        self.args.code_length+self.args.data_flow_length),dtype=np.bool)\n",
    "        #calculate begin index of node and max length of input\n",
    "        node_index=sum([i>1 for i in self.examples[item].position_idx_2])\n",
    "        max_length=sum([i!=1 for i in self.examples[item].position_idx_2])\n",
    "        #sequence can attend to sequence\n",
    "        attn_mask_2[:node_index,:node_index]=True\n",
    "        #special tokens attend to all tokens\n",
    "        for idx,i in enumerate(self.examples[item].input_ids_2):\n",
    "            if i in [0,2]:\n",
    "                attn_mask_2[idx,:max_length]=True\n",
    "        #nodes attend to code tokens that are identified from\n",
    "        for idx,(a,b) in enumerate(self.examples[item].dfg_to_code_2):\n",
    "            if a<node_index and b<node_index:\n",
    "                attn_mask_2[idx+node_index,a:b]=True\n",
    "                attn_mask_2[a:b,idx+node_index]=True\n",
    "        #nodes attend to adjacent nodes\n",
    "        for idx,nodes in enumerate(self.examples[item].dfg_to_dfg_2):\n",
    "            for a in nodes:\n",
    "                if a+node_index<len(self.examples[item].position_idx_2):\n",
    "                    attn_mask_2[idx+node_index,a+node_index]=True\n",
    "                    \n",
    "        return (torch.tensor(self.examples[item].input_ids_1),\n",
    "                torch.tensor(self.examples[item].position_idx_1),\n",
    "                torch.tensor(attn_mask_1), \n",
    "                torch.tensor(self.examples[item].input_ids_2),\n",
    "                torch.tensor(self.examples[item].position_idx_2),\n",
    "                torch.tensor(attn_mask_2),                 \n",
    "                torch.tensor(self.examples[item].label))\n",
    "\n",
    "train_dataset = TextDataset(tokenizer, args, file_path=args.train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size*2, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = x.reshape(-1,x.size(-1)*2)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "        \n",
    "class Model(nn.Module):   \n",
    "    def __init__(self, encoder,config,tokenizer,args):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.config=config\n",
    "        self.tokenizer=tokenizer\n",
    "        self.classifier=RobertaClassificationHead(config)\n",
    "        self.args=args\n",
    "    \n",
    "        \n",
    "    def forward(self, inputs_ids_1,position_idx_1,attn_mask_1,inputs_ids_2,position_idx_2,attn_mask_2,labels=None): \n",
    "        bs,l=inputs_ids_1.size()\n",
    "        inputs_ids=torch.cat((inputs_ids_1.unsqueeze(1),inputs_ids_2.unsqueeze(1)),1).view(bs*2,l)\n",
    "        position_idx=torch.cat((position_idx_1.unsqueeze(1),position_idx_2.unsqueeze(1)),1).view(bs*2,l)\n",
    "        attn_mask=torch.cat((attn_mask_1.unsqueeze(1),attn_mask_2.unsqueeze(1)),1).view(bs*2,l,l)\n",
    "\n",
    "        #embedding\n",
    "        nodes_mask=position_idx.eq(0)\n",
    "        token_mask=position_idx.ge(2)        \n",
    "        inputs_embeddings=self.encoder.roberta.embeddings.word_embeddings(inputs_ids)\n",
    "        nodes_to_token_mask=nodes_mask[:,:,None]&token_mask[:,None,:]&attn_mask\n",
    "        nodes_to_token_mask=nodes_to_token_mask/(nodes_to_token_mask.sum(-1)+1e-10)[:,:,None]\n",
    "        avg_embeddings=torch.einsum(\"abc,acd->abd\",nodes_to_token_mask,inputs_embeddings)\n",
    "        inputs_embeddings=inputs_embeddings*(~nodes_mask)[:,:,None]+avg_embeddings*nodes_mask[:,:,None]    \n",
    "        \n",
    "        outputs = self.encoder.roberta(inputs_embeds=inputs_embeddings,attention_mask=attn_mask,position_ids=position_idx)[0]\n",
    "        logits=self.classifier(outputs)\n",
    "        prob=F.softmax(logits, dim = 1)\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss,prob\n",
    "        else:\n",
    "            return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "09/17/2021 12:57:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, code_length=386, config_name='microsoft/graphcodebert-base', data_flow_length=128, device=device(type='cuda'), do_eval=False, do_test=False, do_train=True, epochs=1, eval_batch_size=16, eval_data_file='../data/clonedetection/valid.txt', evaluate_during_training=True, gradient_accumulation_steps=4, learning_rate=2e-05, max_grad_norm=1.0, max_steps=-1, model_name_or_path='microsoft/graphcodebert-base', n_gpu=1, output_dir='saved_models', seed=123456, test_data_file='../data/clonedetection/test.txt', tokenizer_name='microsoft/graphcodebert-base', train_batch_size=4, train_data_file='../data/clonedetection/train.txt', warmup_steps=0, weight_decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(args.model_name_or_path,config=config)    \n",
    "model = Model(model,config,tokenizer,args)\n",
    "logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "#build dataloader\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size,num_workers=4)\n",
    "\n",
    "args.max_steps=args.epochs*len( train_dataloader)\n",
    "args.save_steps=len( train_dataloader)//10\n",
    "args.warmup_steps=args.max_steps//5\n",
    "model.to(args.device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay': args.weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps,\n",
    "                                            num_training_steps=args.max_steps)\n",
    "\n",
    "# multi-gpu training\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, eval_when_training=False):\n",
    "    #build dataloader\n",
    "    eval_dataset = TextDataset(tokenizer, args, file_path=args.eval_data_file)\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler,batch_size=args.eval_batch_size,num_workers=4)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1 and eval_when_training is False:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "    logits=[]  \n",
    "    y_trues=[]\n",
    "    \n",
    "    \n",
    "    bar = tqdm(eval_dataloader,total=len(eval_dataloader))\n",
    "    for step, batch in enumerate(bar):\n",
    "        (inputs_ids_1,position_idx_1,attn_mask_1,\n",
    "        inputs_ids_2,position_idx_2,attn_mask_2,\n",
    "        labels)=[x.to(args.device)  for x in batch]\n",
    "        with torch.no_grad():\n",
    "            lm_loss,logit = model(inputs_ids_1,position_idx_1,attn_mask_1,\n",
    "                                  inputs_ids_2,position_idx_2,attn_mask_2,labels)\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            y_trues.append(labels.cpu().numpy())\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    #calculate scores\n",
    "    logits=np.concatenate(logits,0)\n",
    "    y_trues=np.concatenate(y_trues,0)\n",
    "    best_threshold=0.5\n",
    "    best_f1=0\n",
    "\n",
    "    y_preds=logits[:,1]>best_threshold\n",
    "    recall=recall_score(y_trues, y_preds)\n",
    "    precision=precision_score(y_trues, y_preds)\n",
    "    f1=f1_score(y_trues, y_preds)             \n",
    "    result = {\n",
    "        \"eval_recall\": float(recall),\n",
    "        \"eval_precision\": float(precision),\n",
    "        \"eval_f1\": float(f1),\n",
    "        \"eval_threshold\":best_threshold,\n",
    "    }\n",
    "\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(round(result[key],4)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2021 12:57:36 - INFO - __main__ -   ***** Running training *****\n",
      "09/17/2021 12:57:36 - INFO - __main__ -     Num examples = 160\n",
      "09/17/2021 12:57:36 - INFO - __main__ -     Num Epochs = 1\n",
      "09/17/2021 12:57:36 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "09/17/2021 12:57:36 - INFO - __main__ -     Total train batch size = 16\n",
      "09/17/2021 12:57:36 - INFO - __main__ -     Gradient Accumulation steps = 4\n",
      "09/17/2021 12:57:36 - INFO - __main__ -     Total optimization steps = 40\n",
      "epoch 0 loss 0.17159:  38%|███████▉             | 15/40 [00:03<00:03,  6.29it/s]09/17/2021 12:57:39 - INFO - __main__ -   Creating features from index file at ../data/clonedetection/valid.txt \n",
      "\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                         | 6/160 [00:00<00:04, 38.36it/s]\u001b[A\n",
      "  6%|██▋                                       | 10/160 [00:00<00:07, 20.95it/s]\u001b[A\n",
      " 10%|████▏                                     | 16/160 [00:00<00:04, 30.67it/s]\u001b[A\n",
      " 13%|█████▌                                    | 21/160 [00:00<00:04, 34.46it/s]\u001b[A\n",
      " 16%|██████▊                                   | 26/160 [00:00<00:03, 35.38it/s]\u001b[A\n",
      " 19%|████████▏                                 | 31/160 [00:00<00:03, 38.00it/s]\u001b[A\n",
      " 22%|█████████▍                                | 36/160 [00:01<00:03, 35.92it/s]\u001b[A\n",
      " 27%|███████████▎                              | 43/160 [00:01<00:02, 44.11it/s]\u001b[A\n",
      " 30%|████████████▌                             | 48/160 [00:01<00:02, 42.52it/s]\u001b[A\n",
      " 34%|██████████████▍                           | 55/160 [00:01<00:02, 47.18it/s]\u001b[A\n",
      " 38%|████████████████                          | 61/160 [00:01<00:01, 49.70it/s]\u001b[A\n",
      " 42%|█████████████████▌                        | 67/160 [00:01<00:01, 47.85it/s]\u001b[A\n",
      " 46%|███████████████████▍                      | 74/160 [00:01<00:01, 51.34it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 80/160 [00:01<00:01, 53.05it/s]\u001b[A\n",
      " 54%|██████████████████████▊                   | 87/160 [00:01<00:01, 56.98it/s]\u001b[A\n",
      " 58%|████████████████████████▍                 | 93/160 [00:02<00:01, 57.61it/s]\u001b[A\n",
      " 62%|█████████████████████████▉                | 99/160 [00:02<00:01, 55.43it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 107/160 [00:02<00:00, 59.77it/s]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 114/160 [00:02<00:00, 58.24it/s]\u001b[A\n",
      " 78%|███████████████████████████████▊         | 124/160 [00:02<00:00, 69.39it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 132/160 [00:02<00:00, 66.98it/s]\u001b[A\n",
      " 88%|████████████████████████████████████▏    | 141/160 [00:02<00:00, 71.97it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 149/160 [00:02<00:00, 68.67it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 160/160 [00:03<00:00, 52.74it/s]\u001b[A\n",
      "09/17/2021 12:57:42 - INFO - __main__ -   ***** Running evaluation *****\n",
      "09/17/2021 12:57:42 - INFO - __main__ -     Num examples = 160\n",
      "09/17/2021 12:57:42 - INFO - __main__ -     Batch size = 16\n",
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████▍                                       | 1/10 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 20%|████████▊                                   | 2/10 [00:00<00:01,  4.19it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 3/10 [00:00<00:01,  4.55it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 4/10 [00:00<00:01,  4.75it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 5/10 [00:01<00:01,  4.89it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 6/10 [00:01<00:00,  4.99it/s]\u001b[A\n",
      " 70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  5.05it/s]\u001b[A\n",
      " 80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  5.08it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  5.12it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 10/10 [00:02<00:00,  4.79it/s]\u001b[A\n",
      "09/17/2021 12:57:44 - INFO - __main__ -   ***** Eval results *****\n",
      "09/17/2021 12:57:44 - INFO - __main__ -     eval_f1 = 0.2022\n",
      "09/17/2021 12:57:44 - INFO - __main__ -     eval_precision = 0.1125\n",
      "09/17/2021 12:57:44 - INFO - __main__ -     eval_recall = 1.0\n",
      "09/17/2021 12:57:44 - INFO - __main__ -     eval_threshold = 0.5\n",
      "epoch 0 loss 0.17824:  78%|████████████████▎    | 31/40 [00:11<00:01,  6.05it/s]09/17/2021 12:57:47 - INFO - __main__ -   Creating features from index file at ../data/clonedetection/valid.txt \n",
      "\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|█▌                                         | 6/160 [00:00<00:03, 50.12it/s]\u001b[A\n",
      "  8%|███▏                                      | 12/160 [00:00<00:02, 52.87it/s]\u001b[A\n",
      " 11%|████▋                                     | 18/160 [00:00<00:04, 30.79it/s]\u001b[A\n",
      " 14%|█████▊                                    | 22/160 [00:00<00:05, 25.71it/s]\u001b[A\n",
      " 16%|██████▊                                   | 26/160 [00:00<00:05, 25.38it/s]\u001b[A\n",
      " 21%|████████▉                                 | 34/160 [00:01<00:03, 35.71it/s]\u001b[A\n",
      " 24%|██████████▏                               | 39/160 [00:01<00:04, 28.02it/s]\u001b[A\n",
      " 28%|███████████▌                              | 44/160 [00:01<00:03, 31.02it/s]\u001b[A\n",
      " 31%|█████████████▏                            | 50/160 [00:01<00:03, 36.23it/s]\u001b[A\n",
      " 34%|██████████████▍                           | 55/160 [00:01<00:02, 38.94it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 64/160 [00:01<00:02, 44.69it/s]\u001b[A\n",
      " 43%|██████████████████                        | 69/160 [00:01<00:02, 39.61it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 77/160 [00:02<00:01, 46.99it/s]\u001b[A\n",
      " 52%|█████████████████████▊                    | 83/160 [00:02<00:01, 44.84it/s]\u001b[A\n",
      " 56%|███████████████████████▋                  | 90/160 [00:02<00:01, 49.09it/s]\u001b[A\n",
      " 60%|█████████████████████████▏                | 96/160 [00:02<00:01, 50.97it/s]\u001b[A\n",
      " 64%|██████████████████████████▏              | 102/160 [00:02<00:01, 50.23it/s]\u001b[A\n",
      " 68%|███████████████████████████▉             | 109/160 [00:02<00:00, 53.51it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 117/160 [00:02<00:00, 55.71it/s]\u001b[A\n",
      " 78%|███████████████████████████████▊         | 124/160 [00:02<00:00, 57.83it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 133/160 [00:03<00:00, 63.14it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 140/160 [00:03<00:00, 51.00it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 146/160 [00:03<00:00, 52.44it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 160/160 [00:03<00:00, 44.82it/s]\u001b[A\n",
      "09/17/2021 12:57:51 - INFO - __main__ -   ***** Running evaluation *****\n",
      "09/17/2021 12:57:51 - INFO - __main__ -     Num examples = 160\n",
      "09/17/2021 12:57:51 - INFO - __main__ -     Batch size = 16\n",
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|████▍                                       | 1/10 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 20%|████████▊                                   | 2/10 [00:00<00:01,  4.21it/s]\u001b[A\n",
      " 30%|█████████████▏                              | 3/10 [00:00<00:01,  4.61it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 4/10 [00:00<00:01,  4.79it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 5/10 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 6/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      " 70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  5.03it/s]\u001b[A\n",
      " 80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  5.07it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  5.09it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 10/10 [00:02<00:00,  4.78it/s]\u001b[A\n",
      "09/17/2021 12:57:53 - INFO - __main__ -   ***** Eval results *****\n",
      "09/17/2021 12:57:53 - INFO - __main__ -     eval_f1 = 0.2486\n",
      "09/17/2021 12:57:53 - INFO - __main__ -     eval_precision = 0.1419\n",
      "09/17/2021 12:57:53 - INFO - __main__ -     eval_recall = 1.0\n",
      "09/17/2021 12:57:53 - INFO - __main__ -     eval_threshold = 0.5\n",
      "epoch 0 loss 0.1779: 100%|██████████████████████| 40/40 [00:19<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "logger.info(\"  Num Epochs = %d\", args.epochs)\n",
    "logger.info(\"  Instantaneous batch size per GPU = %d\", args.train_batch_size//max(args.n_gpu, 1))\n",
    "logger.info(\"  Total train batch size = %d\",args.train_batch_size*args.gradient_accumulation_steps)\n",
    "logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "logger.info(\"  Total optimization steps = %d\", args.max_steps)\n",
    "\n",
    "global_step=0\n",
    "tr_loss, logging_loss,avg_loss,tr_nb,tr_num,train_loss = 0.0, 0.0,0.0,0,0,0\n",
    "best_f1=0\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "for idx in range(args.epochs): \n",
    "    bar = tqdm(train_dataloader,total=len(train_dataloader))\n",
    "    tr_num=0\n",
    "    train_loss=0\n",
    "    for step, batch in enumerate(bar):\n",
    "        (inputs_ids_1,position_idx_1,attn_mask_1,\n",
    "        inputs_ids_2,position_idx_2,attn_mask_2,\n",
    "        labels)=[x.to(args.device)  for x in batch]\n",
    "        model.train()\n",
    "        loss,logits = model(inputs_ids_1,position_idx_1,attn_mask_1,\n",
    "                            inputs_ids_2,position_idx_2,attn_mask_2,labels)\n",
    "\n",
    "        if args.n_gpu > 1:\n",
    "            loss = loss.mean()\n",
    "\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        tr_num+=1\n",
    "        train_loss+=loss.item()\n",
    "        if avg_loss==0:\n",
    "            avg_loss=tr_loss\n",
    "\n",
    "        avg_loss=round(train_loss/tr_num,5)\n",
    "        bar.set_description(\"epoch {} loss {}\".format(idx,avg_loss))\n",
    "\n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()  \n",
    "            global_step += 1\n",
    "            output_flag=True\n",
    "            avg_loss=round(np.exp((tr_loss - logging_loss) /(global_step- tr_nb)),4)\n",
    "\n",
    "            if global_step % args.save_steps == 0:\n",
    "                results = evaluate(args, model, tokenizer, eval_when_training=True)\n",
    "\n",
    "                # Save model checkpoint\n",
    "                if results['eval_f1']>best_f1:\n",
    "                    best_f1=results['eval_f1']\n",
    "                    best_model=model\n",
    "#                     logger.info(\"  \"+\"*\"*20)  \n",
    "#                     logger.info(\"  Best f1:%s\",round(best_f1,4))\n",
    "#                     logger.info(\"  \"+\"*\"*20)                          \n",
    "\n",
    "#                     checkpoint_prefix = 'checkpoint-best-f1'\n",
    "#                     output_dir = os.path.join(args.output_dir, '{}'.format(checkpoint_prefix))                        \n",
    "#                     if not os.path.exists(output_dir):\n",
    "#                         os.makedirs(output_dir)                        \n",
    "#                     model_to_save = model.module if hasattr(model,'module') else model\n",
    "#                     output_dir = os.path.join(output_dir, '{}'.format('model.bin')) \n",
    "#                     torch.save(model_to_save.state_dict(), output_dir)\n",
    "#                     logger.info(\"Saving model checkpoint to %s\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/17/2021 12:57:55 - INFO - __main__ -   Creating features from index file at ../data/clonedetection/test.txt \n",
      "100%|█████████████████████████████████████████| 160/160 [00:02<00:00, 54.68it/s]\n",
      "09/17/2021 12:57:59 - INFO - __main__ -   ***** Running Test *****\n",
      "09/17/2021 12:57:59 - INFO - __main__ -     Num examples = 160\n",
      "09/17/2021 12:57:59 - INFO - __main__ -     Batch size = 16\n",
      "09/17/2021 12:58:01 - INFO - __main__ -   ***** Test results *****\n",
      "09/17/2021 12:58:01 - INFO - __main__ -     eval_f1 = 0.1639\n",
      "09/17/2021 12:58:01 - INFO - __main__ -     eval_precision = 0.1282\n",
      "09/17/2021 12:58:01 - INFO - __main__ -     eval_recall = 0.2273\n",
      "09/17/2021 12:58:01 - INFO - __main__ -     eval_threshold = 0.5\n"
     ]
    }
   ],
   "source": [
    "def test(args, model, tokenizer, best_threshold=0):\n",
    "    #build dataloader\n",
    "    eval_dataset = TextDataset(tokenizer, args, file_path=args.test_data_file)\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size,num_workers=4)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running Test *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "    logits=[]  \n",
    "    y_trues=[]\n",
    "    for batch in eval_dataloader:\n",
    "        (inputs_ids_1,position_idx_1,attn_mask_1,\n",
    "        inputs_ids_2,position_idx_2,attn_mask_2,\n",
    "        labels)=[x.to(args.device)  for x in batch]\n",
    "        with torch.no_grad():\n",
    "            lm_loss,logit = model(inputs_ids_1,position_idx_1,attn_mask_1,inputs_ids_2,position_idx_2,attn_mask_2,labels)\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            y_trues.append(labels.cpu().numpy())\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    #calculate scores\n",
    "    logits=np.concatenate(logits,0)\n",
    "    y_trues=np.concatenate(y_trues,0)\n",
    "    best_threshold=0.5\n",
    "    best_f1=0\n",
    "\n",
    "    y_preds=logits[:,1]>best_threshold\n",
    "    recall=recall_score(y_trues, y_preds)\n",
    "    precision=precision_score(y_trues, y_preds)   \n",
    "    f1=f1_score(y_trues, y_preds)             \n",
    "    result = {\n",
    "        \"eval_recall\": float(recall),\n",
    "        \"eval_precision\": float(precision),\n",
    "        \"eval_f1\": float(f1),\n",
    "        \"eval_threshold\":best_threshold,\n",
    "    }\n",
    "\n",
    "    logger.info(\"***** Test results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(round(result[key],4)))\n",
    "    \n",
    "#     #output result\n",
    "#     logits=np.concatenate(logits,0)\n",
    "#     y_preds=logits[:,1]>best_threshold\n",
    "#     with open(os.path.join(args.output_dir,\"predictions.txt\"),'w') as f:\n",
    "#         for example,pred in zip(eval_dataset.examples,y_preds):\n",
    "#             if pred:\n",
    "#                 f.write(example.url1+'\\t'+example.url2+'\\t'+'1'+'\\n')\n",
    "#             else:\n",
    "#                 f.write(example.url1+'\\t'+example.url2+'\\t'+'0'+'\\n')\n",
    "test(args, best_model, tokenizer,best_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
