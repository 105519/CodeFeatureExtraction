{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "# os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import tokenize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM, RobertaTokenizer\n",
    "from transformers import WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
    "# from parser import remove_comments_and_docstrings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/graphs2.jsonl', 'r')\n",
    "graphs2 = json.loads(f.readline())\n",
    "f.close()\n",
    "f = open('../data/labels01.jsonl', 'r')\n",
    "labels01 = json.loads(f.readline())\n",
    "f.close()\n",
    "topic_number = len(labels01[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 25\n",
    "args.input_limit = 10\n",
    "args.gradient_accumulation_steps = 32\n",
    "\n",
    "args.total_length = 512\n",
    "args.graph_length = 200\n",
    "args.max_grad_norm = 1.0\n",
    "args.learning_rate = 1e-5\n",
    "args.weight_decay = 0.0\n",
    "args.adam_epsilon = 1e-8\n",
    "\n",
    "args.current_topic = 0\n",
    "args.topic_number = topic_number\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "args.seed = 978438233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def set_seed():\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "set_seed()\n",
    "\n",
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "config.num_labels = 1\n",
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')\n",
    "pretrain_model = RobertaForMaskedLM.from_pretrained('microsoft/codebert-base', config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12272/12272 [00:53<00:00, 229.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for E, y in tqdm(zip(graphs2, labels01), total = len(graphs2)):\n",
    "    if (sum(y) != 0):\n",
    "        V = [[1] + [0 for i in range(384 - 1)] for j in range(200)]\n",
    "        dataset.append([0, V, E, y])\n",
    "random.shuffle(dataset)\n",
    "\n",
    "# dataset = []\n",
    "# for (V, E), y in tqdm(zip(graphs2, labels01), total = len(graphs2)):\n",
    "#     if (sum(y) != 0):\n",
    "#         for i in range(200 - len(V)):\n",
    "#             V.append([0] * 384)\n",
    "#         dataset.append([0, V, E, y])\n",
    "# random.shuffle(dataset)\n",
    "\n",
    "# dataset = []\n",
    "# for (V, E), y in tqdm(zip(graphs2, labels01), total = len(graphs2)):\n",
    "#     if (sum(y) != 0):\n",
    "# #         nodes = sentence_model.encode(V).tolist()\n",
    "# #         for i in range(args.graph_length - len(nodes)):\n",
    "# #             nodes.append([0] * 384)\n",
    "# #         edges = [[] for t in nodes]\n",
    "# #         for u, v in E:\n",
    "# #             edges[u].append(v)\n",
    "#         dataset.append([0, V, E, y])\n",
    "# #     if (len(dataset) == 400): # TODO\n",
    "# #         break # TODO\n",
    "# random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        code, V, M, labels = self.examples[item]\n",
    "        return 0, 0, torch.tensor(V), M, torch.Tensor([labels[args.current_topic]])\n",
    "\n",
    "test_data = TextDataset(dataset[int(len(dataset) * 0.75) :])\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, drop_last = False)#, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.W = nn.Linear(384 * 2, 384)\n",
    "        self.dense = nn.Linear(384, 40)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(args.graph_length * 40, 2)\n",
    "        \n",
    "    def forward(self, code_ids, position_ids, nodes, edges, labels):\n",
    "        nodes = nodes.view(args.graph_length, -1)\n",
    "        labels = labels.view(-1)\n",
    "        for k in range(20):\n",
    "            new_nodes = []\n",
    "            for u in range(nodes.size(0)):\n",
    "                h = torch.zeros(384).to(args.device)\n",
    "                V = random.sample(edges[u], min(5, len(edges[u])))\n",
    "                for v in V:\n",
    "                    h += nodes[v] / len(V)\n",
    "                h = torch.cat((nodes[u], h))\n",
    "                h = F.relu(self.W(h))\n",
    "                new_nodes.append(h / (h * h).sum())\n",
    "            nodes = torch.stack(new_nodes, dim = 0)\n",
    "        y = nodes\n",
    "        y = self.dropout(y)\n",
    "        y = F.relu(self.dense(y).view(-1))\n",
    "        y = self.dropout(y)\n",
    "        y = self.out_proj(y)\n",
    "        y = F.softmax(y, dim = 0)[1:]\n",
    "        loss_function = MSELoss()\n",
    "        loss = loss_function(y.view(-1), labels.view(-1))\n",
    "        return y, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, epoch_id):\n",
    "    loss_sum = 0\n",
    "    loss_cnt = 0\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    bar = tqdm(test_dataloader, total = len(test_dataloader))\n",
    "    for data in bar:\n",
    "        code_ids, position_ids, nodes, edges, labels = data\n",
    "        code_ids = code_ids.to(args.device)\n",
    "        position_ids = position_ids.to(args.device)\n",
    "        nodes = nodes.to(args.device)\n",
    "        edges = [[b.item() for b in a] for a in edges]\n",
    "        labels = labels.to(args.device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            prob, loss = model(code_ids, position_ids, nodes, edges, labels)\n",
    "            prob = prob.view(-1)\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "            loss_sum = loss_sum + loss.item() * code_ids.size(0)\n",
    "            loss_cnt = loss_cnt + code_ids.size(0)\n",
    "            y_preds.append((prob > 0.5).long().cpu().numpy())\n",
    "            y_trues.append(labels.long().view(-1).cpu().numpy())\n",
    "    y_trues = np.concatenate(y_trues, 0)\n",
    "    y_preds = np.concatenate(y_preds, 0)\n",
    "    TP = sum([x == 1 and y == 1 for x, y in zip(y_trues, y_preds)])\n",
    "    FP = sum([x == 0 and y == 1 for x, y in zip(y_trues, y_preds)])\n",
    "    TN = sum([x == 0 and y == 0 for x, y in zip(y_trues, y_preds)])\n",
    "    FN = sum([x == 1 and y == 0 for x, y in zip(y_trues, y_preds)])\n",
    "    print('TP FP TN FN =', TP, FP, TN, FN)\n",
    "\n",
    "    f1 = float(f1_score(y_trues, y_preds))\n",
    "    rs = float(recall_score(y_trues, y_preds))\n",
    "    ps = float(precision_score(y_trues, y_preds))\n",
    "    os.system('mkdir -p result')\n",
    "    print('f1:', f1)\n",
    "    print('recall:', rs)\n",
    "    print('precision:', ps)\n",
    "    print('loss:', loss_sum / loss_cnt)\n",
    "    f = open('result/graphSAGE' + str(args.current_topic).zfill(2) + '-' + str(epoch_id).zfill(3) + '.txt', 'w')\n",
    "    print(f1, rs, ps, loss_sum / loss_cnt, TP, FP, TN, FN, file = f)\n",
    "    f.close()\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:27<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:31<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:39<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:23<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:33<00:00,  2.40s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3068/3068 [41:58<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN = 206 1715 1046 101\n",
      "f1: 0.18491921005385997\n",
      "recall: 0.6710097719869706\n",
      "precision: 0.10723581467985424\n",
      "loss: 0.25089930140229993\n",
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:46<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:08<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:04<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:16<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:20<00:00,  2.40s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3068/3068 [41:29<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP TN FN = 181 1322 1439 126\n",
      "f1: 0.2\n",
      "recall: 0.5895765472312704\n",
      "precision: 0.12042581503659348\n",
      "loss: 0.25127091364646054\n",
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:55<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:37<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1910/1910 [1:16:31<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "topic 0 epoch 2:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 1777/1910 [1:10:58<04:55,  2.22s/it]"
     ]
    }
   ],
   "source": [
    "def get_dataloader():\n",
    "    posi_data = []\n",
    "    nega_data = []\n",
    "    for x in dataset[: int(len(dataset) * 0.75)]:\n",
    "        if (x[3][args.current_topic]):\n",
    "            posi_data.append(x)\n",
    "        else:\n",
    "            nega_data.append(x)\n",
    "    print(len(posi_data), len(nega_data))\n",
    "    if (len(posi_data) < len(nega_data)):\n",
    "        nega_data = random.sample(nega_data, max(1, len(posi_data)))\n",
    "    train_data = TextDataset(posi_data + nega_data)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler = train_sampler, drop_last = False)#, num_workers = 4)\n",
    "    return train_dataloader\n",
    "\n",
    "for i in range(args.topic_number):\n",
    "    args.current_topic = i\n",
    "    model = Model(pretrain_model, config)\n",
    "    model.to(args.device)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = args.learning_rate)\n",
    "    \n",
    "    for epoch_num in range(args.epochs):\n",
    "        step = 0\n",
    "        for t in range(5):\n",
    "            train_dataloader = get_dataloader()\n",
    "            bar = tqdm(train_dataloader, total = len(train_dataloader))\n",
    "            for data in bar:\n",
    "                code_ids, position_ids, nodes, edges, labels = data\n",
    "                code_ids = code_ids.to(args.device)\n",
    "                position_ids = position_ids.to(args.device)\n",
    "                nodes = nodes.to(args.device)\n",
    "                edges = [[b.item() for b in a] for a in edges]\n",
    "                labels = labels.to(args.device)\n",
    "                model.train()\n",
    "                _, loss = model(code_ids, position_ids, nodes, edges, labels)\n",
    "                if args.n_gpu > 1:\n",
    "                    loss = loss.mean()\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                bar.set_description(\"topic {} epoch {}\".format(i, epoch_num))\n",
    "                step += 1\n",
    "                if (step % args.gradient_accumulation_steps == 0):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "        if (step % args.gradient_accumulation_steps != 0):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        evaluate(model, epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heyuxuan",
   "language": "python",
   "name": "heyuxuan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
