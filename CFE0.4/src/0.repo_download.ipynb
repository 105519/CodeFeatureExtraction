{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "# topics\n",
    "topics = ['3d', 'algorithm', 'android', 'ansible', 'api', 'aws',\n",
    "'azure', 'bash', 'bitcoin', 'bot', 'cli', 'compiler', 'covid-19',\n",
    "'css', 'data-structures', 'data-visualization', 'database',\n",
    "'deep-learning', 'django', 'docker', 'documentation',\n",
    "'ethereum', 'flask', 'framework', 'git', 'google',\n",
    "'graphql', 'hacktoberfest', 'html', 'http', 'ios', 'javascript',\n",
    "'jquery', 'json', 'jupyter-notebook', 'kubernetes', 'latex',\n",
    "'library', 'linux', 'machine-learning', 'macos', 'markdown',\n",
    "'minecraft', 'mongodb', 'monitoring', 'mysql', 'nlp', 'nodejs',\n",
    "'parsing', 'php', 'postgresql', 'qt', 'raspberry-pi', 'react',\n",
    "'rest-api', 'scikit-learn', 'security', 'server', 'serverless',\n",
    "'shell', 'sql', 'telegram', 'tensorflow', 'terminal', 'terraform',\n",
    "'testing', 'twitter', 'ubuntu', 'vim', 'webapp', 'windows', 'xml']\n",
    "\n",
    "# tokens, the more the better\n",
    "tokens = ['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',\n",
    "          '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',\n",
    "          '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',\n",
    "          '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']\n",
    "def get_token():\n",
    "    return tokens[random.randint(0, len(tokens) - 1)]\n",
    "\n",
    "# dir where save the data\n",
    "repo_saving_dir = './github-repos/'\n",
    "\n",
    "fail_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_worker(response):\n",
    "    code_info = response.json()\n",
    "    if \"?\" in response.url:  # distinguish folder url\n",
    "        url_info = response.url.split(\"?\")[0].split('/')\n",
    "        repo_name = url_info[4] + '/' + url_info[5] + \"/\" + \"/\".join(url_info[7:])\n",
    "    else:  # single file\n",
    "        url_info = response.url.split('/')\n",
    "        repo_name = url_info[4] + '/' + url_info[5]\n",
    "\n",
    "    for repo_code in code_info:\n",
    "        if repo_code['type'] == \"dir\":\n",
    "            # recursively download files that are in folders\n",
    "            response = requests.get(repo_code['url'], headers={'Authorization': 'token ' + get_token()})\n",
    "            download_worker(response)\n",
    "        download_url = repo_code['download_url']\n",
    "        file_name = repo_code['name']\n",
    "        if download_url == None:\n",
    "            continue\n",
    "        if not file_name.endswith('.py'): # skip non-python file,\n",
    "            continue\n",
    "        if not os.path.exists(f'{repo_saving_dir}/files/{repo_name}'):\n",
    "            os.makedirs(f'{repo_saving_dir}/files/{repo_name}')\n",
    "        # skip downloads that would download to existing files (overwriting them)\n",
    "        subprocess.run([\"wget\", \"-nc\", \"-nv\", download_url, \"--output-document\",\n",
    "                        f'{repo_saving_dir}/files/{repo_name}/{file_name}'])\n",
    "def download_code(item):\n",
    "    # check if downloaded it before\n",
    "    repo_full_name = item['full_name']\n",
    "    if (repo_full_name in topic_map):\n",
    "        return 1\n",
    "    try:\n",
    "        token_index = random.randint(0, len(tokens) - 1)\n",
    "        contents_url = 'https://api.github.com/repos/' + repo_full_name + '/contents'\n",
    "        response = requests.get(contents_url, headers={'Authorization': 'token ' + tokens[token_index]})\n",
    "        download_worker(response)\n",
    "    except BaseException as e:\n",
    "        print('[Exception]', e, flush=True)\n",
    "        fail_list.append([repo_full_name, str(e)])\n",
    "        return 0\n",
    "    else:\n",
    "        if not os.path.exists(f'{repo_saving_dir}/item/{repo_full_name}'):\n",
    "            os.makedirs(f'{repo_saving_dir}/item/{repo_full_name}')\n",
    "        f = open(f'{repo_saving_dir}/item/{repo_full_name}/item.jsonl', 'w')\n",
    "        json.dump(item, fp = f)\n",
    "        f.close()\n",
    "        topic_map[repo_full_name] = item['topics']\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete non-python files in dir 'path'\n",
    "# def clear_dir(path):\n",
    "#     if (os.path.islink(path)):\n",
    "#         os.unlink(path)\n",
    "#         return 0\n",
    "#     elif (os.path.isfile(path)):\n",
    "#         if (path[-3 :] == '.py'):\n",
    "#             return 1\n",
    "#         else:\n",
    "#             os.remove(path)\n",
    "#             return 0\n",
    "#     else:\n",
    "#         assert os.path.isdir(path), 'This is not file, dir or link: ' + path\n",
    "#         cnt = 0\n",
    "#         for x in os.listdir(path):\n",
    "#             cnt = cnt + clear_dir(path + '/' + x)\n",
    "#         if (cnt == 0):\n",
    "#             os.rmdir(path)\n",
    "#         return cnt\n",
    "\n",
    "# def crawl_repo(item):\n",
    "#     # check if downloaded it before\n",
    "#     if (item['full_name'] in topic_map):\n",
    "#         return 1\n",
    "\n",
    "#     try:\n",
    "#         username = item['owner']['login']\n",
    "#         reponame = item['name']\n",
    "#         dirpath = repo_saving_dir + 'files/' + username + '/'\n",
    "#         filepath = dirpath + reponame + '.zip'\n",
    "#         os.system('mkdir -p ' + dirpath)\n",
    "\n",
    "#         # download and unzip\n",
    "#         assert os.system('curl -H \"Authorization: ' + get_token()\n",
    "#                          + '\" -L ' + item['url'] + '/zipball'\n",
    "#                          + ' --output ' + filepath + ' >/dev/null 2>&1') == 0, \\\n",
    "#                'Error when downloading repo: ' + item['full_name']\n",
    "#         assert os.path.isfile(filepath), 'Zip pack download fail, repo name: ' + item['full_name']\n",
    "#         assert os.system('unzip ' + filepath + ' -d ' + dirpath + ' >/dev/null 2>&1') == 0, \\\n",
    "#                'Error when unziping, pack name: ' + filepath\n",
    "\n",
    "#         # rename the dir name\n",
    "#         prefix = username + '-' + reponame\n",
    "#         cnt = 0\n",
    "#         for x in os.listdir(dirpath):\n",
    "#             if (os.path.isdir(dirpath + x) and x[: len(prefix)] == prefix):\n",
    "#                 cnt += 1\n",
    "#                 wrong_name = x\n",
    "#         assert cnt == 1, 'Zip pack format error, pack name: ' + filepath\n",
    "#         assert os.system('mv ' + dirpath + wrong_name + ' ' + dirpath + reponame) == 0, \\\n",
    "#                'Zip pack format error, pack name: ' + filepath\n",
    "\n",
    "#         # delete non-python files\n",
    "#         cnt = clear_dir(dirpath + reponame)\n",
    "#         assert cnt <= 2000, 'Repo has to many python files, repo name: ' + item['full_name']\n",
    "#     except BaseException as e:\n",
    "#         print('[Exception]', e)\n",
    "#         fail_list.append(item)\n",
    "#         return 0\n",
    "#     else:\n",
    "#         topic_map[item['full_name']] = item['topics']\n",
    "#         return 1\n",
    "\n",
    "def crawl_topic(topic):\n",
    "    # ask number of repos with given topic\n",
    "    url = 'https://api.github.com/search/repositories?q=language:python+topic:' + topic + '&per_page=100&page=1'\n",
    "    data = requests.get(url, headers = {'Authorization' : 'token ' + get_token(),\n",
    "                                        'Accept' : 'application/vnd.github.mercy-preview+json'}).json()\n",
    "    print('-----Working on topic {' + topic + '}: try to get', min(1000, data['total_count']), 'repos-----')\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(min(10, (data['total_count'] + 99) // 100)):\n",
    "        # get the i-th page\n",
    "        url = 'https://api.github.com/search/repositories?q=language:python+topic:' \\\n",
    "              + topic + '&per_page=100&page=' + str(i + 1)\n",
    "        data = requests.get(url, headers = {'Authorization' : 'token ' + get_token(),\n",
    "                                            'Accept' : 'application/vnd.github.mercy-preview+json'}).json()\n",
    "        \n",
    "        # get each repo on this page\n",
    "        for item in data['items']:\n",
    "            # cnt = cnt + crawl_repo(item)\n",
    "            cnt = cnt + download_code(item)\n",
    "    print('-----Topic {' + topic + '} ends: successfully got', cnt, 'repos in total-----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Working on topic {3d}: try to get 455 repos-----\n",
      "-----Topic {3d} ends: successfully got 1 repos in total-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "os.system('rm ' + repo_saving_dir + ' -r -f')\n",
    "topic_map = dict()\n",
    "##################################################\n",
    "# Use the code above if you want to delete the previously downloaded repos\n",
    "# Use the code below if you don't\n",
    "##################################################\n",
    "# f = open('./data/github-repos/topic_map.jsonl', 'r')\n",
    "# topic_map = json.loads(f.readline())\n",
    "# f.close()\n",
    "##################################################\n",
    "\n",
    "for x in topics:\n",
    "    crawl_topic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a1studmuffin/SpaceshipGenerator': ['3d', 'blender-scripts', 'game-development', 'procedural-generation', 'python', 'spaceship']}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(repo_saving_dir):\n",
    "    os.makedirs(repo_saving_dir)\n",
    "f = open(repo_saving_dir + 'topic_map.jsonl', 'w')\n",
    "json.dump(topic_map, fp = f)\n",
    "f.close()\n",
    "\n",
    "f = open(repo_saving_dir + 'fail_list.jsonl', 'w')\n",
    "json.dump(fail_list, fp = f)\n",
    "f.close()\n",
    "\n",
    "print(topic_map)\n",
    "print(fail_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
